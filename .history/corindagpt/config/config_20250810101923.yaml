openai_api_key: "YOUR_OPENAI_API_KEY"
elevenlabs_api_key: "YOUR_ELEVENLABS_API_KEY"
model_names:
  text: "gpt-4o-mini"
  transcription: "whisper-1"
performance_plan: [1]
transcription:
  provider: "elevenlabs"
  # The service will try models in order; falls back on error
  models: ["gpt-4o-transcribe", "whisper-1"]
  model: "whisper-1"
  language: "en"
  prompt: "Common phrases: Hello testing, testing one two"
  streaming_enabled: false
  elevenlabs:
    endpoint: "https://api.elevenlabs.io/v1/speech-to-text"
    model: "scribe_v1"
    diarize: true
    tag_audio_events: true
    language_code: null  # use ISO like 'eng'; auto if null; 'en' will map to 'eng'

transitions:
  phase_transition:
    hotkey: "f11"
    long_press_ms: 3000
  llm_phase_control:
    enabled: false
    keyphrases: ["next phase", "advance phase", "switch to phase {n}"]

tts:
  provider: "elevenlabs"
  streaming_enabled: true
  output_format: "pcm_16000"
  playback:
    backend: "elevenlabs"
    warmup_ms: 0
    settle_ms: 0
    preroll_ms: 0
    start_delay_ms: 0
  debug:
    save_last_wav: true
    path: "last_tts.wav"
  elevenlabs:
    voice_id: "pPdl9cQBQq4p6mRkZy2Z"
    model_id: "eleven_multilingual_v2"
    voice_settings:
      stability: 0.40
      speed: 0.90
      similarity_boost: 0.40
      style: 0.00
      use_speaker_boost: false
