# Story 1.4: End-to-End "Hello World" Pipeline

## Status
- In Progress

## Story
**As a** Magician-Developer, **I want** to trigger a hardcoded request to the LLM and have its response converted to speech and played back, **so that** the fundamental, end-to-end `asyncio` pipeline and its latency can be verified.

## Acceptance Criteria
1. The `gpt.py` module makes a successful asynchronous API call to OpenAI using `httpx` and the configured API key.
2. The `text_to_speech.py` module makes a successful asynchronous API call to the chosen TTS service (e.g., ElevenLabs) using the configured API key.
3. After receiving a transcript (from Story 1.3), the `main.py` loop triggers a simple, hardcoded request to the LLM (e.g., "Tell me a short, one-sentence joke").
4. The text response from the LLM is passed directly to the TTS module.
5. The resulting audio is played back through the system's default speakers.
6. The entire process, from the LLM API call to the end of audio playback, is non-blocking and managed by the `asyncio` event loop.

## Tasks / Subtasks
- [ ] Implement GPT service (AC: 1, 3)
  - [x] Create `src/services/gpt.py` with `async generate_response(prompt: str) -> str`
  - [x] Use `httpx.AsyncClient` with base URL and API key from config [Source: docs/architecture.md#3. Tech Stack; docs/architecture.md#6. External APIs]
  - [x] Minimal prompt: one-sentence joke; return text string
- [ ] Implement TTS service (AC: 2, 4, 5)
  - [x] Create `src/services/tts.py` with `async synthesize(text: str) -> bytes` and `async play(audio_bytes: bytes) -> None`
  - [ ] Call ElevenLabs streaming endpoint, collect audio bytes [Source: docs/architecture.md#6. External APIs]
  - [ ] Play via default audio device; ensure non-blocking behavior in event loop
- [ ] Wire end-to-end in main loop (AC: 3â€“6)
  - [ ] After transcript is available, call GPT with hardcoded prompt
  - [ ] Pass response to TTS, play audio
  - [ ] Ensure all awaits are non-blocking; use `logging` for diagnostics [Source: docs/architecture.md#2. High Level Architecture; docs/architecture.md#13. Coding Standards]
- [ ] Configuration updates
  - [x] Ensure `config.yaml` includes required OpenAI and ElevenLabs settings (model name, voice id, API keys) [Source: docs/prd.md#Technical Assumptions]
  - [ ] Load via existing initialization utilities [Source: docs/architecture.md#5. Components]
- [ ] Unit tests
  - [ ] Mock `httpx` calls for GPT and TTS; verify prompt and auth headers
  - [ ] Verify audio bytes are returned and `play()` invoked
  - [ ] Confirm main flow awaits GPT then TTS, and uses logging (no print)

## Dev Notes

- File Locations
  - GPT service: `src/services/gpt.py` [Source: docs/architecture.md#10. Source Tree]
  - TTS service: `src/services/tts.py` [Source: docs/architecture.md#10. Source Tree]
  - Entry point/orchestrator: `src/__main__.py` [Source: docs/architecture.md#10. Source Tree]

- Architecture & External APIs
  - All external calls must be asynchronous using `httpx` [Source: docs/architecture.md#3. Tech Stack]
  - OpenAI and ElevenLabs are the standard providers [Source: docs/architecture.md#6. External APIs]
  - Follow the primary workflow order for the sustained input path [Record -> Transcribe -> Decode -> LLM -> TTS -> Playback] [Source: docs/architecture.md#7. Core Workflows]

- Coding Standards & Performance
  - Non-blocking `asyncio` throughout; avoid synchronous I/O [Source: docs/architecture.md#2. High Level Architecture]
  - Use `logging` module; format with Black; explicit exception handling [Source: docs/architecture.md#13. Coding Standards]

- Testing Guidance
  - Unit + integration with pytest; mock external APIs (`pytest-httpx`) [Source: docs/architecture.md#14. Test Strategy and Standards]
  - Add an integration-style test that exercises the main loop with mocked GPT and TTS

## Change Log
| Date | Version | Description | Author |
| :--- | :--- | :--- | :--- |
| 2025-08-07 | 0.1 | Initial draft created from PRD and architecture. | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
{{agent_model_name_version}}

### Debug Log References

### Completion Notes List

### File List

## QA Results
