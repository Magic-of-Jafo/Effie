# Story 2.3: Dynamic Prompt Loading with LangChain

## Status
- Draft

## Story
As a Magician-Developer, I want the application to load different LLM prompts from external files based on the current performance phase, so that I can easily customize the AI's personality and behavior without changing any code.

## Acceptance Criteria
1. Five placeholder prompt files (e.g., `phase_1_prompt.txt`, `phase_2_prompt.txt`) are created in a `prompts` directory. [Source: docs/prd.md#story-23-dynamic-prompt-loading-with-langchain]
2. The application uses `langchain-core`'s `PromptTemplate` to load and parse the prompt file that corresponds to the `current_phase`. [Source: docs/prd.md#story-23-dynamic-prompt-loading-with-langchain]
3. The hardcoded prompt from Story 1.4 is now replaced with the dynamically loaded prompt. [Source: docs/prd.md#story-23-dynamic-prompt-loading-with-langchain]
4. The system gracefully handles a missing prompt file by logging an error and using a default, generic fallback prompt. [Source: docs/prd.md#story-23-dynamic-prompt-loading-with-langchain]

## Tasks / Subtasks
- [ ] Prompt files & structure (AC: 1)
  - [ ] Add placeholder files under `corindagpt/prompts/`: `phase_1_prompt.txt` … `phase_5_prompt.txt`
  - [ ] Include simple templates with variables like `{transcript}` and `{secret}` (future)
  - [ ] Confirm path aligns with source tree [Source: docs/architecture.md#10.-source-tree]
- [ ] Prompt loading service (AC: 2, 4)
  - [ ] Create `src/services/prompt_loader.py` exposing:
    - [ ] `load_prompt_for_phase(phase:int) -> PromptTemplate`
    - [ ] `render_prompt(template: PromptTemplate, context: dict) -> str`
    - [ ] Graceful fallback: default template + log warning on missing file
  - [ ] Use `langchain-core` `PromptTemplate` [Source: docs/architecture.md#3.-tech-stack]
- [ ] GPT integration (AC: 2–3)
  - [ ] Update `src/services/gpt.py` to accept a rendered prompt string
  - [ ] Replace any hardcoded prompt from Story 1.4 with the rendered prompt based on `current_phase`
- [ ] Main loop wiring (AC: 2–4)
  - [ ] In `src/__main__.py`, before calling GPT, load the prompt for the `current_phase` and render with context (at minimum `{transcript}`)
  - [ ] If prompt load fails, log warning and use fallback prompt
- [ ] Logging & errors (AC: 4)
  - [ ] Ensure prompt not found, parse errors, or missing variables are logged with `logging` [Source: docs/architecture.md#13.-coding-standards]
- [ ] Verification
  - [ ] Manual: switch phases (2.2) and observe different prompts used
  - [ ] Manual: temporarily remove one prompt file to confirm fallback logging

## Dev Notes
- Architecture references
  - Use `langchain-core` for prompt templating [Source: docs/architecture.md#3.-tech-stack]
  - Place prompt files under `corindagpt/prompts/` per source tree [Source: docs/architecture.md#10.-source-tree]
  - Integrate with existing pipeline: Record -> Transcribe -> Decode (future) -> LLM -> TTS [Source: docs/architecture.md#7.-core-workflows]
  - Components: add `prompt_loader.py`; integrate in `__main__.py` and `gpt.py` [Source: docs/architecture.md#5.-components]
- Standards & performance
  - Keep operations non-blocking; all I/O via `asyncio` where applicable [Source: docs/architecture.md#2.-high-level-architecture]
  - Use `logging` for diagnostics; no prints [Source: docs/architecture.md#13.-coding-standards]

## Project Structure Notes
- New file `src/services/prompt_loader.py` follows service placement; prompt assets live under `corindagpt/prompts/` as defined.

## Change Log
| Date | Version | Description | Author |
| :--- | :--- | :--- | :--- |
| 2025-08-08 | 0.1 | Draft created from PRD and architecture. | Scrum Master |

## Dev Agent Record

### Completion Notes List
- N/A (draft)

### QA Results
- N/A (draft)

## Story Draft Checklist Validation

- [x] Goal & Context Clarity
- [x] Technical Implementation Guidance
- [x] Reference Effectiveness
- [x] Self-Containment Assessment
- [x] Testing Guidance

| Category                             | Status | Issues |
| ------------------------------------ | ------ | ------ |
| 1. Goal & Context Clarity            | PASS   |        |
| 2. Technical Implementation Guidance | PASS   |        |
| 3. Reference Effectiveness           | PASS   |        |
| 4. Self-Containment Assessment       | PASS   |        |
| 5. Testing Guidance                  | PASS   |        |

**Final Assessment:** READY

- Sufficient context to implement; references and paths align with architecture; fallbacks defined for robustness.
