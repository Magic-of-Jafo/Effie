# Story 1.2: Basic Audio Input Capture

## Status
- Done

## Story
**As a** Magician-Developer, **I want** the application to listen for and capture audio from a microphone upon a specific keyboard input, **so that** my spoken commands can be recorded for processing.

## Acceptance Criteria
1. The `main.py` event loop can successfully detect a keyboard input (e.g., the F12 key being pressed and held).
2. Upon detecting the input, the `voice_to_text.py` module is triggered and begins recording audio from the system's default microphone.
3. The recording stops when the keyboard input is released.
4. The captured audio shall be mono-channel and prepared in a format suitable for efficient, low-latency network transmission (e.g., an in-memory buffer for streaming or a compressed format like MP3).
5. A confirmation message (e.g., "Audio captured") is printed to the console for verification.

## Tasks / Subtasks
- [x] Implement basic press-and-hold detection in the main asyncio loop (AC: 1, 3)
  - [x] Use `src/__main__.py` as entry point; detect key press and release events for F12
  - [x] Ensure non-blocking behavior within the asyncio loop
- [x] Create `src/services/voice_to_text.py` with async recording API (AC: 2, 4)
  - [x] Start recording from default microphone on request
  - [x] Capture mono audio and expose an in-memory buffer suitable for low-latency transmission
  - [x] Provide stop function that returns the captured buffer
  - [x] Base implementation on `SpeechRecognition` per tech stack
  - [ ] Reference: [Source: docs/architecture.md#3. Tech Stack], [Source: docs/architecture.md#5. Components]
- [x] Wire main loop to voice capture and confirmation logging (AC: 2, 5)
  - [x] On press: start recording; on release: stop and retrieve buffer
  - [x] Log "Audio captured" via `logging` module (not print)
  - [ ] Reference: [Source: docs/architecture.md#13. Coding Standards], [Source: docs/architecture.md#10. Source Tree]
- [x] Unit tests for input-to-recording flow (AC: 1–5)
  - [x] Mock key events and `voice_to_text` start/stop
  - [x] Verify mono buffer and confirmation log message
  - [ ] Reference: [Source: docs/architecture.md#14. Test Strategy and Standards]

## Dev Notes

- Previous Story Insights
  - Project structure, centralized config, and test scaffolding are in place per Story 1.1. Adhere to the defined source tree and coding standards.
  - Configuration loading exists (`src/utils/initialization.py`), so avoid hardcoding paths or secrets.

- File Locations
  - Entry point: `src/__main__.py` [Source: docs/architecture.md#10. Source Tree]
  - Voice capture service: `src/services/voice_to_text.py` [Source: docs/architecture.md#10. Source Tree]

- Technology and Libraries
  - Use `SpeechRecognition` (3.10.x) for microphone capture [Source: docs/architecture.md#3. Tech Stack]
  - Use `asyncio` throughout the main loop [Source: docs/architecture.md#2. High Level Architecture]

- Components and Responsibilities
  - Voice to Text component is responsible for capturing audio from the microphone and returning a buffer [Source: docs/architecture.md#5. Components]

- Coding Standards
  - Use `logging` for diagnostics; no `print()` [Source: docs/architecture.md#13. Coding Standards]
  - Format code with Black; write explicit exception handling where appropriate [Source: docs/architecture.md#13. Coding Standards]

- Testing
  - Follow unit + integration approach with pytest; mock external I/O where needed [Source: docs/architecture.md#14. Test Strategy and Standards]
  - Focus tests on: key press/hold detection, start/stop recording calls, mono buffer shape, and confirmation log.

- Technical Constraints / Notes
  - Keep operations non-blocking to preserve low-latency pipeline requirements [Source: docs/architecture.md#2. High Level Architecture]
  - No REST endpoints are hosted by this app [Source: docs/architecture.md#8. REST API Spec]

## Change Log
| Date | Version | Description | Author |
| :--- | :--- | :--- | :--- |
| 2025-08-07 | 0.1 | Initial draft created from PRD and architecture. | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
BMad Master (GPT-5)

### Debug Log References
- pytest: 4 passed
- runtime: F12 press/release produced 'Audio captured'

### Completion Notes List
- AC1–AC3: F12 press/hold triggers start, release stops (non-blocking)
- AC4: mono WAV bytes returned from in-memory buffer
- AC5: confirmation logged via logging module

### File List
- corindagpt/src/__main__.py
- corindagpt/src/components/input_handler.py
- corindagpt/src/services/voice_to_text.py
- corindagpt/src/components/__init__.py
- corindagpt/src/services/__init__.py
- corindagpt/src/__init__.py
- corindagpt/tests/test_input_recording_flow.py
- corindagpt/tests/test_initialization.py

## QA Results
- Unit: 4 passed
- Manual: OK (see logs)
